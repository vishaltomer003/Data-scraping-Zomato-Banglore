{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TABLE ONE"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["#Required python libraries"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re\n","import requests\n","from bs4 import BeautifulSoup\n","from selenium import webdriver\n","from selenium.webdriver.common.keys import Keys\n","from selenium.webdriver.common.by import By\n","import time\n","from geopy.exc import GeocoderTimedOut\n","from geopy.geocoders import Nominatim\n","import numpy as np\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# driver and browser\n","url ='https://www.zomato.com/bangalore/'\n","driver = webdriver.Firefox()\n","driver.get(url)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# Clicking \" see more\"  button.\n","button = driver.find_elements(By.XPATH, \"//div[contains(text(),'see more')]\")\n","button[0].click()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# defining BeautifulSoup library\n","soup = BeautifulSoup(driver.page_source,\"html.parser\")"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["29\n"]}],"source":["# collection all the location LINKS by using Beautifulsoup in list called LOCATIONLIST\n","locationlist = []\n","for link in soup.find_all('a', href = True):\n","    if 'https://www.zomato.com/bangalore/' in link['href']:\n","        locationlist.append(link['href'])\n","print(len(locationlist))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# getting all types of link  from all the links in locationlist\n","link = []\n","for i in range(len(locationlist)):\n","    driver.get(locationlist[i])\n","    time.sleep(1)  # Allow 2 seconds for the web page to (open depends on you)\n","    scroll_pause_time = 2 # You can set your own pause time. dont slow too slow that might not able to load more data\n","    screen_height = driver.execute_script(\"return window.screen.height;\")  # get the screen height of the web\n","    A = 1\n","\n","    while True:\n","        # scroll one screen height each time\n","        driver.execute_script(\"window.scrollTo(0, {screen_height}*{A});\".format(screen_height=screen_height, A=A))\n","        A += 1\n","        time.sleep(scroll_pause_time)\n","        # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n","        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")\n","        # Break the loop when the height we need to scroll to is larger than the total scroll height\n","        if (screen_height) * A > scroll_height:\n","            break\n","\n","    links = driver.find_elements('tag name','a')\n","    for i in links:\n","        link.append(i.get_attribute('href'))"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# separating Restaurant links from all the links in list called LIST\n","Restaurant_link=[]\n","for i in link:\n","    try:\n","        if 'order' in i:\n","            Restaurant_link.append(i)\n","    except:\n","        pass"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# deleting the reaping link by make the list to set\n","final_Restaurant_link = set(Restaurant_link)\n","print(len(final_Restaurant_link))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# making it list from set\n","Restaurants=[]\n","for i in final_Restaurant_link:\n","    try:\n","        if 'order' in i:\n","            Restaurants.append(i)\n","    except:\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# price_for_one\n","price_for_one = []\n","count = 0\n","remove_order = [i.replace('/order','') for i in Restaurants['link']]\n","for i in range(len(remove_order)):\n","    count+=1\n","    print (count, end =\" \")\n","    driver.get(remove_order[i])\n","    try:\n","        price = driver. find_element (By.XPATH, \"//p[contains(text(), 'â‚¹')]\")\n","        price_for_one.append (price.text)\n","    except:\n","        price_for_one.append (np.nan)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 "]}],"source":["# adding values in different types of atributes\n","name=[]\n","rating=[]\n","cusines=[]\n","location=[]\n","delivery_review_number=[]\n","count = 0\n","for i in Restaurants:\n","    count+=1\n","    print(count,end=\" \")\n","    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n","    r=requests.get(i,headers=headers).text\n","    sou = BeautifulSoup(r, 'lxml')\n","    try:\n","        j = sou.find_all(\"h1\",{\"class\" : \"sc-7kepeu-0 sc-eilVRo eAhpQG\"})\n","        name.append(j[0].text)\n","    except:\n","        name.append('NA')\n","    try:\n","        j = sou.find_all(\"div\",{\"class\" : \"sc-1q7bklc-1 cILgox\"})\n","        rating.append(j[1].text)\n","    except:\n","        rating.append('NA')\n","    \n","    try:\n","        j = sou.find_all(\"div\",{\"class\" : \"sc-eMigcr fAGAHS\"})\n","        cusines.append(j[0].text)\n","    except:\n","        cusines.append('NA')\n","    try:\n","        j = sou.find_all(\"a\",{\"class\" : \"sc-cpmLhU fDVcNc\"})\n","        location.append(j[0].text)\n","    except:\n","        location.append('NA')\n","\n","    try:\n","        j = sou.find_all(\"div\",{\"class\" : \"sc-1q7bklc-8 kEgyiI\"})\n","        delivery_review_number.append(j[1].text)\n","    except:\n","        delivery_review_number.append('NA')\n","    \n","\n","    \n","    "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# converting it in data frame\n","col=['name','rating','cusines','delivery_review_number','location','price_for_one']\n","df=pd.DataFrame({'Name': name,'Rating':rating,'cusines':cusines,'delivery_review_number':delivery_review_number,'location':location,'price_for_one':price_for_one})\n"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["#  adding longitude and latitude of different locations to data frame\n","longitude = []\n","latitude = []\n","   \n","# function to find the coordinate\n","# of a given city \n","def findGeocode(location): \n","    try:\n","        geolocator = Nominatim(user_agent=\"chrome\")\n","          \n","        return geolocator.geocode(location)\n","      \n","    except GeocoderTimedOut:\n","          \n","        return findGeocode(location)  \n","for i in (df[\"location\"]):\n","      \n","    if findGeocode(i) != None:\n","           \n","        loc = findGeocode(i)\n","        latitude.append(loc.latitude)\n","        longitude.append(loc.longitude)\n","\n","    else:\n","        latitude.append(np.nan)\n","        longitude.append(np.nan)\n","\n","df[\"Longitude\"] = longitude\n","df[\"Latitude\"] = latitude\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# adding all  the location links to data frame\n","df[\"Restaurant_link\"]  = Restaurants\n","df"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# converting dataframe in csv and downloading it.\n","df.to_csv(r\"C:\\Users\\Vaishali Tomar\\Desktop\\zomato_project\\restaurant_info.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TABLE TWO"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["restaurant_name = []\n","dish_name = []\n","dish_price = []\n","location=[]\n","count = 0\n","\n","for i in Restaurants :\n","    count+=1\n","    print(count,end=\" \")\n","    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n","    r=requests.get(i,headers=headers).text\n","    sou = BeautifulSoup(r, 'lxml')\n","    for i in range(10):\n","        try:\n","            j = sou.find_all(\"h4\",{\"class\" : \"sc-1s0saks-15 iSmBPS\"})\n","            dish_name.append(j[i].text)\n","        except:\n","            dish_name.append('NA')\n","        try:\n","            j = sou.find_all(\"span\",{\"class\" : \"sc-17hyc2s-1 cCiQWA\"})\n","            dish_price.append(j[i].text)\n","        except:\n","            dish_price.append('NA')\n","        try:\n","            j = sou.find_all(\"h1\",{\"class\" : \"sc-7kepeu-0 sc-eilVRo eAhpQG\"})#sc-7kepeu-0 sc-eilVRo eAhpQG\n","            restaurant_name.append(j[0].text)\n","        except:\n","            restaurant_name.append('NA')\n","        try:\n","            j = sou.find_all(\"a\",{\"class\" : \"sc-cpmLhU fDVcNc\"})\n","            location.append(j[0].text)\n","        except:\n","            location.append('NA')\n","col=['location','restaurant_name','dish_name','cusines','dish_price']\n","df1=pd.DataFrame({'location':location,'restaurant_name': restaurant_name,'dish_name':dish_name,'dish_price':dish_price})\n","df1.to_csv(r\"C:\\Users\\Vaishali Tomar\\Desktop\\zomato_project\\restaurant_details\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# converting it to data frame\n","col=['restaurant_name','dish_name','cusines','dish_price']\n","df1=pd.DataFrame({'restaurant_name': restaurant_name,'dish_name':dish_name,'dish_price':dish_price})\n","df1"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# downloading and converting it to csv\n","df1.to_csv(r\"C:\\Users\\Vaishali Tomar\\Desktop\\zomato_project\\restaurant_details.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"043f2b5a1970a131d06754b308e1494d14bec9888fec20f91acc177f4f73a177"}}},"nbformat":4,"nbformat_minor":4}
